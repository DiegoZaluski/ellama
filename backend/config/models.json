{
  "download_path": "../../../../llama.cpp/models",
  "temp_path": "../../../../llama.cpp/models/.tmp",
  "log_path": "./logs",
  "win_download_path": "..\\..\\..\\..\\llama.cpp\\models",
  "win_temp_path": "..\\..\\..\\..\\llama.cpp\\models\\.tmp",
  "win_log_path": ".\\logs",
  "timeout": 7200,
  "stall_timeout": 120,
  "allowed_domains": ["huggingface.co", "hf.co"],
  "ram_download_threshold_gb": 2.5,
  "models": [
    {
      "id": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
      "name": "Llama 3.2 3B",
      "filename": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
      "size_gb": 2.1,
      "urls": [
        "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf",
        "https://hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf"
      ]
    },
    {
      "id": "qwen2.5-7b-instruct.Q4_K_M.gguf",
      "name": "Qwen 2.5 7B",
      "filename": "qwen2.5-7b-instruct-q4_k_m.gguf",
      "size_gb": 4.5,
      "urls": [
        "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q4_k_m.gguf"
      ]
    },
    {
      "id": "llama-3.1-8b-instruct.Q4_K_M.gguf",
      "name": "Llama 3.1 8B",
      "filename": "llama-3.1-8b-instruct.Q4_K_M.gguf",
      "size_gb": 5.2,
      "urls": [
        "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf"
      ]
    },
    {
      "id": "deepseek-coder-6.7b-instruct.Q4_K_M.gguf",
      "name": "DeepSeek Coder",
      "filename": "deepseek-coder-6.7b-instruct.Q4_K_M.gguf",
      "size_gb": 4.2,
      "urls": [
        "https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q4_K_M.gguf"
      ]
    },
    {
      "id": "Llama-3.2-1B-Instruct-Q4_K_M.gguf",
      "name": "Llama 3.2 1B",
      "filename": "Llama-3.2-1B-Instruct-Q4_K_M.gguf",
      "size_gb": 1.1,
      "urls": [
        "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_M.gguf"
      ]
    },
    {
      "id": "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
      "name": "TinyLlama 1.1B",
      "filename": "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
      "size_gb": 0.8,
      "urls": [
        "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"
      ]
    },
    {
      "id": "zephyr-7b-beta.Q4_K_M.gguf",
      "name": "Zephyr 7B",
      "filename": "zephyr-7b-beta.Q4_K_M.gguf",
      "size_gb": 4.7,
      "urls": [
        "https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/resolve/main/zephyr-7b-beta.Q4_K_M.gguf"
      ]
    },
    {
      "id": "neural-chat-7b-v3-3.Q4_K_M.gguf",
      "name": "Neural Chat 7B",
      "filename": "neural-chat-7b-v3-3.Q4_K_M.gguf",
      "size_gb": 4.6,
      "urls": [
        "https://huggingface.co/TheBloke/neural-chat-7B-v3-3-GGUF/resolve/main/neural-chat-7b-v3-3.Q4_K_M.gguf"
      ]
    },
    {
      "id": "qwen2.5-1.5b-instruct.Q4_K_M.gguf",
      "name": "Qwen 2.5 1.5B",
      "filename": "qwen2.5-1.5b-instruct.Q4_K_M.gguf",
      "size_gb": 1.3,
      "urls": [
        "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct.Q4_K_M.gguf"
      ]
    },
    {
      "id": "codegeex4-all-9b-Q6_K.gguf",
      "name": "CodeGeeX4 9B",
      "filename": "codegeex4-all-9b-Q6_K.gguf",
      "size_gb": 6.0,
      "urls": [
        "https://huggingface.co/bartowski/codegeex4-all-9b-GGUF/resolve/main/codegeex4-all-9b-Q6_K.gguf"
      ]
    },
     {
      "id": "mistral-7b-openorca.Q4_K_M.gguf",
      "name": "Mistral 7B OpenOrca",
      "filename": "mistral-7b-openorca.Q4_K_M.gguf",
      "size_gb": 4.5,
      "urls": [
        "https://huggingface.co/TheBloke/Mistral-7B-OpenOrca-GGUF/resolve/main/mistral-7b-openorca.Q4_K_M.gguf"
      ]
    },
    {
      "id": "dolphin-2.6-mistral-7b.Q4_K_M.gguf",
      "name": "Dolphin 2.6 Mistral 7B",
      "filename": "dolphin-2.6-mistral-7b.Q4_K_M.gguf",
      "size_gb": 4.5,
      "urls": [
        "https://huggingface.co/TheBloke/dolphin-2.6-mistral-7b-GGUF/resolve/main/dolphin-2.6-mistral-7b.Q4_K_M.gguf"
      ]
    },
    {
      "id": "orca-2-7b.Q4_K_M.gguf",
      "name": "Orca 2 7B",
      "filename": "orca-2-7b.Q4_K_M.gguf",
      "size_gb": 4.3,
      "urls": [
        "https://huggingface.co/TheBloke/Orca-2-7B-GGUF/resolve/main/orca-2-7b.Q4_K_M.gguf"
      ]
    },
    {
      "id": "solar-10.7b-instruct-v1.0.Q4_K_M.gguf",
      "name": "SOLAR 10.7B Instruct",
      "filename": "solar-10.7b-instruct-v1.0.Q4_K_M.gguf",
      "size_gb": 6.5,
      "urls": [
        "https://huggingface.co/TheBloke/SOLAR-10.7B-Instruct-v1.0-GGUF/resolve/main/solar-10.7b-instruct-v1.0.Q4_K_M.gguf"
      ]
    },
    {
      "id": "openhermes-2.5-mistral-7b.Q4_K_M.gguf",
      "name": "OpenHermes 2.5 Mistral 7B",
      "filename": "openhermes-2.5-mistral-7b.Q4_K_M.gguf",
      "size_gb": 4.5,
      "urls": [
        "https://huggingface.co/TheBloke/OpenHermes-2.5-Mistral-7B-GGUF/resolve/main/openhermes-2.5-mistral-7b.Q4_K_M.gguf"
      ]
    },
    {
      "id": "mythomax-l2-13b.Q5_K_M.gguf",
      "name": "MythoMax L2 13B",
      "filename": "mythomax-l2-13b.Q5_K_M.gguf",
      "size_gb": 8.0,
      "urls": [
        "https://huggingface.co/TheBloke/MythoMax-L2-13B-GGUF/resolve/main/mythomax-l2-13b.Q5_K_M.gguf"
      ]
    },
    {
      "id": "codellama-7b-instruct.Q4_K_M.gguf",
      "name": "CodeLlama 7B Instruct",
      "filename": "codellama-7b-instruct.Q4_K_M.gguf",
      "size_gb": 4.0,
      "urls": [
        "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_K_M.gguf"
      ]
    },
    {
      "id": "phind-codellama-34b-v2.Q4_K_M.gguf",
      "name": "Phind CodeLlama 34B v2",
      "filename": "phind-codellama-34b-v2.Q4_K_M.gguf",
      "size_gb": 9.5,
      "urls": [
        "https://huggingface.co/TheBloke/Phind-CodeLlama-34B-v2-GGUF/resolve/main/phind-codellama-34b-v2.Q4_K_M.gguf"
      ]
    },
    {
      "id": "xwin-lm-7b-v0.1.Q4_K_M.gguf",
      "name": "Xwin-LM 7B v0.1",
      "filename": "xwin-lm-7b-v0.1.Q4_K_M.gguf",
      "size_gb": 4.3,
      "urls": [
        "https://huggingface.co/TheBloke/Xwin-LM-7B-V0.1-GGUF/resolve/main/xwin-lm-7b-v0.1.Q4_K_M.gguf"
      ]
    },
    {
      "id": "chinese-alpaca-2-7b.Q4_K_M.gguf",
      "name": "Chinese Alpaca 2 7B",
      "filename": "chinese-alpaca-2-7b.Q4_K_M.gguf",
      "size_gb": 4.4,
      "urls": [
        "https://huggingface.co/TheBloke/chinese-alpaca-2-7B-GGUF/resolve/main/chinese-alpaca-2-7b.Q4_K_M.gguf"
      ]
    },
    {
      "id": "Meta-Llama-3.1-8B-Instruct-abliterated-Q4_K_M.gguf",
      "name": "Llama 3.1 8B Abliterated",
      "filename": "Meta-Llama-3.1-8B-Instruct-abliterated-Q4_K_M.gguf",
      "size_gb": 4.9,
      "urls": [
        "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-abliterated-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-abliterated-Q4_K_M.gguf"
      ]
    }

  ]
}
