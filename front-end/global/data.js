// Dados para os elementos (inalterado)
export const headerTabsContent = ["Configuração", "Documentação", "Contribuições"];

// Dados com detalhes auxiliares para as caixas maiores (inalterado)
export const topCardsDetails = [
  { title: "Models", detail: "Hello World. TEST UI OPTIONS CARDS.", indicator: "test - I love you" },
  { title: "Chat", detail: "Hello World. TEST UI OPTIONS CARDS.", indicator: "test - I love you" },
  { title: "Workflows Lib", detail: "Hello World. TEST UI OPTIONS CARDS.", indicator: "test - I love you" },
  { title: "customization", detail: "Hello World. TEST UI OPTIONS CARDS.", indicator: "test - I love you" },
  { title: "IDE", detail: "Hello World. TEST UI OPTIONS CARDS.", indicator: "test - I love you" },
];

export const modelCardsDetails = [
  {
    modelName: "Llama 3.2 3B",
    memoryUsage: "2.1 GB RAM",
    intelligenceLevel: "Fast",
    fullModelName: "Llama-3.2-3B-Instruct-Q4_K_M.gguf"
  },
  {
    modelName: "Mistral 7B",
    memoryUsage: "4.5 GB RAM",
    intelligenceLevel: "High",
    fullModelName: "mistral-7b-instruct-v0.3.Q4_K_M.gguf"
  },
  {
    modelName: "Qwen2.5 7B",
    memoryUsage: "4.8 GB RAM", 
    intelligenceLevel: "Very High",
    fullModelName: "qwen2.5-7b-instruct.Q4_K_M.gguf"
  },
  {
    modelName: "Llama 3.1 8B",
    memoryUsage: "5.2 GB RAM",
    intelligenceLevel: "Maximum",
    fullModelName: "llama-3.1-8b-instruct.Q4_K_M.gguf"
  },
  {
    modelName: "DeepSeek Coder",
    memoryUsage: "4.2 GB RAM",
    intelligenceLevel: "Code Specialist",
    fullModelName: "deepseek-coder-6.7b-instruct.Q4_K_M.gguf"
  },
  {
    modelName: "Phi-3 Mini",
    memoryUsage: "2.5 GB RAM",
    intelligenceLevel: "Balanced",
    fullModelName: "phi-3-mini-4k-instruct.Q4_K_M.gguf"
  },
  {
  modelName: "Llama 3.2 1B",
  memoryUsage: "1.1 GB RAM",
  intelligenceLevel: "Ultra Fast",
  fullModelName: "Llama-3.2-1B-Instruct-Q4_K_M.gguf"
},
{
  modelName: "TinyLlama 1.1B",
  memoryUsage: "0.8 GB RAM",
  intelligenceLevel: "Ultra Fast",
  fullModelName: "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"
},
{
  modelName: "Zephyr 7B",
  memoryUsage: "4.7 GB RAM",
  intelligenceLevel: "Very High",
  fullModelName: "zephyr-7b-beta.Q4_K_M.gguf"
},
{
  modelName: "Neural Chat 7B",
  memoryUsage: "4.6 GB RAM",
  intelligenceLevel: "Very High",
  fullModelName: "neural-chat-7b-v3-3.Q4_K_M.gguf"
},
{
  modelName: "Openchat 3.6",
  memoryUsage: "4.9 GB RAM",
  intelligenceLevel: "Very High",
  fullModelName: "openchat-3.6-8b-20240522.Q4_K_M.gguf"
}
];

export const deepResearchModels = [
  "mistral-7b-instruct-v0.3.Q4_K_M.gguf",
  "qwen2.5-7b-instruct.Q4_K_M.gguf", 
  "llama-3.1-8b-instruct.Q4_K_M.gguf",
  "zephyr-7b-beta.Q4_K_M.gguf",
  "neural-chat-7b-v3-3.Q4_K_M.gguf",
  "openchat-3.6-8b-20240522.Q4_K_M.gguf"
];

export const simpleModel = [
  "Llama-3.2-1B-Instruct-Q4_K_M.gguf",
  "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"
];